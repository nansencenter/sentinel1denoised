{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified: 25/10/2020 by DD\n",
    "#\n",
    "# In this quick start practical tutorial, you will learn how to get the noise scaling factors from\n",
    "# a number of S1 Level-1 GRD training files.\n",
    "# The processing comprises two stages. 1st is related to the method called 'experiment_noiseScaling'\n",
    "# of the 'Sentinel1Image' class to obtain statistics for each individual training file.\n",
    "# The aggregated statistics processing is the second stage of the method and implemnted as a\n",
    "# python script called 'analyze_experiment_noiseScalingParameters.py'.\n",
    "# In this tutorial we follow the mentioned implementation almost line by line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-requerments: It is assumed that you have downloaded and installed Sentinel1Denoised package:\n",
    "# https://github.com/nansencenter/sentinel1denoised/tree/master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# Stage 1. Processing of individual training files (S1 Level-1 GRD)    #\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01:16:27|40|nansat|_get_dataset_metadata|GDAL could not open /mnt/sverdrup-2/sat_auxdata/denoise/dolldrums/zip/S1A_IW_GRDH_1SDV_20200607T075151_20200607T075220_032908_03CFD7_9E14.zip, trying to read with Nansat mappers...\n"
     ]
    }
   ],
   "source": [
    "# First you need to import Sentinel1Image class and open \n",
    "# a S1 Level1 GRD file (IW GRDH in our case, replace with yours)\n",
    "# Note: In our example we process the only one training file but in real data processing you need to use tens of files\n",
    "# in batch manner\n",
    "\n",
    "from s1denoise import Sentinel1Image\n",
    "import numpy as np\n",
    "from scipy.optimize import fminbound\n",
    "s1 = Sentinel1Image('/mnt/sverdrup-2/sat_auxdata/denoise/dolldrums/zip/S1A_IW_GRDH_1SDV_20200607T075151_20200607T075220_032908_03CFD7_9E14.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We further go almost in line by line manner through the method called 'experiment_noiseScaling'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clip size of side pixels, ~1km\n",
    "cPx = {'IW':100, 'EW':25}[s1.obsMode]\n",
    "# Define polarization of the data we want to process\n",
    "polarization = 'VH'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call 'subswathIndexMap' method to get matrix with sub-swath numbers consistent with the data grid\n",
    "subswathIndexMap = s1.subswathIndexMap(polarization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 3, 3, 3],\n",
       "       [1, 1, 1, ..., 3, 3, 3],\n",
       "       [1, 1, 1, ..., 3, 3, 3]], dtype=uint8)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out the matrix\n",
    "subswathIndexMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f4aa8ace7d0>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lets visualize the sub-swath numbers\n",
    "# Color corresponds to different sub-swath. In our case:\n",
    "# blue - 1, green - 2, yellow - 3, black - no data\n",
    "import matplotlib.pyplot as plt\n",
    "plt.clf()\n",
    "plt.imshow(subswathIndexMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To mask areas over land, we call 'landmask'\n",
    "landmask = s1.landmask(skipGCP=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get matrices of calibrated raw sigma zero and NESZ from ESA-provided annotaion files\n",
    "sigma0 = s1.rawSigma0Map(polarization)\n",
    "noiseEquivalentSigma0 = s1.rawNoiseEquivalentSigma0Map(polarization, lutShift=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the line indexes where we have data for the each element in range ditrection\n",
    "import numpy as np\n",
    "validLineIndices = np.argwhere(np.sum(subswathIndexMap!=0,axis=1)==s1.shape()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define number of lines to averge (block height), in our case 1000 px\n",
    "# and calculate the block bounds\n",
    "numberOfLinesToAverage = 1000\n",
    "blockBounds = np.arange(validLineIndices.min(), validLineIndices.max(),\n",
    "                                numberOfLinesToAverage, dtype='uint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1367,  2367,  3367,  4367,  5367,  6367,  7367,  8367,  9367,\n",
       "       10367, 11367, 12367, 13367, 14367, 15367, 16367, 17367, 18367,\n",
       "       19367], dtype=uint64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out block bounds coordinates (pixel indexes)\n",
    "blockBounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare a dictonary for results for each sub-block in each sub-swath\n",
    "# sigma0 is a vector that is mean range profile\n",
    "# noiseEquivalentSigma0 is a vector with ESA-provided mean range noise profile\n",
    "# scalingFactor is a value with intermediate noise scaling factor\n",
    "# correlationCoefficient is a value with correlation coefficient between raw sigma0 and scaled nosie\n",
    "# fitResidual is a value with error of fitting of the seclected scaling factor (K)\n",
    "results = { '%s%s' % (s1.obsMode, li):\n",
    "                        { 'sigma0':[],\n",
    "                          'noiseEquivalentSigma0':[],\n",
    "                          'scalingFactor':[],\n",
    "                          'correlationCoefficient':[],\n",
    "                          'fitResidual':[] }\n",
    "                    for li in range(1, {'IW':3, 'EW':5}[s1.obsMode]+1) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over blocks\n",
    "for iBlk in range(len(blockBounds)-1):\n",
    "    # Check if there is no pixels over land areas\n",
    "    if landmask[blockBounds[iBlk]:blockBounds[iBlk+1]].sum() != 0:\n",
    "        continue\n",
    "    \n",
    "    # Slicing 2D arrays for each block\n",
    "    # sigma0\n",
    "    blockS0 = sigma0[blockBounds[iBlk]:blockBounds[iBlk+1],:]   \n",
    "    # raw ESA noise\n",
    "    blockN0 = noiseEquivalentSigma0[blockBounds[iBlk]:blockBounds[iBlk+1],:]\n",
    "    # Sub-swath indices for the block\n",
    "    blockSWI = subswathIndexMap[blockBounds[iBlk]:blockBounds[iBlk+1],:]\n",
    "    \n",
    "    # An arbitrary empirical adjustment.\n",
    "    # When the number of valid range pixels is too small, it is hard to get reliable estimation.\n",
    "    # By allowing the use of some pixels with negative values, the number of range pixels to be used \n",
    "    # for fitting increases.\n",
    "    # In short, it can be any value but we set it as 0.5 for no special reason.\n",
    "    pixelValidity = (np.nanmean(blockS0 - blockN0 * 0.5, axis=0) > 0) \n",
    "\n",
    "    fitCoefficients = []\n",
    "    \n",
    "    # Loop over sub-blocks in sub-swaths\n",
    "    for iSW in range(1, {'IW': 3, 'EW': 5}[s1.obsMode]+1):\n",
    "        subswathID = '%s%s' % (s1.obsMode, iSW)\n",
    "        # Get valid pixel indices based on 'pixelValidity'\n",
    "        pixelIndex = np.nonzero((blockSWI==iSW).sum(axis=0) * pixelValidity)[0][cPx:-cPx]\n",
    "        if pixelIndex.sum()==0:\n",
    "            continue\n",
    "            \n",
    "        # Compute mean range profiles for sub-block by averaging in azimuth direction\n",
    "        meanS0 = np.nanmean(np.where(blockSWI==iSW, blockS0, np.nan), axis=0)[pixelIndex]\n",
    "        meanN0 = np.nanmean(np.where(blockSWI==iSW, blockN0, np.nan), axis=0)[pixelIndex]\n",
    "        \n",
    "        # Calculate weight that is proportional to gradient of sigma0 that takes account of sigma0 varying\n",
    "        weight = abs(np.gradient(meanN0))\n",
    "        # Normilize the weight\n",
    "        weight = weight / weight.sum() * np.sqrt(len(weight))\n",
    "        \n",
    "        # Polyfit is used only to return error (second return param) when fitting func:\n",
    "        # s0-k*no = f(A*x + B). Where:\n",
    "        # s0 - sigma0\n",
    "        # n0 - ESA-provided thermal noise\n",
    "        # k - noise scaling (to be identified at later stage of fitting)\n",
    "        # x - pixel index\n",
    "        # A, B - just some polynom coeffs that are not used\n",
    "        errFunc = lambda k,x,s0,n0,w: np.polyfit(x,s0-k*n0,w=w,deg=1,full=True)[1].item()\n",
    "        \n",
    "        # Now with polynom fitting function in place, K (the noise scaling coefficient)\n",
    "        # is fitted iteratively using 'fminbound' method from NumPy for the interval of 0 to 3dB\n",
    "        scalingFactor = fminbound(errFunc, 0, 3,\n",
    "            args=(pixelIndex,meanS0,meanN0,weight), disp=False).item()\n",
    "        # Value of correlation coefficient between sigma0 and scaled noise\n",
    "        correlationCoefficient = np.corrcoef(meanS0, scalingFactor * meanN0)[0,1]\n",
    "        # Value of error of the fitting of the selected scaling factor (K)\n",
    "        fitResidual = np.polyfit(pixelIndex, meanS0 - scalingFactor * meanN0,\n",
    "                                 w=weight, deg=1, full=True)[1].item()\n",
    "\n",
    "        # Append results to the list\n",
    "        results[subswathID]['sigma0'].append(meanS0)\n",
    "        results[subswathID]['noiseEquivalentSigma0'].append(meanN0)\n",
    "        results[subswathID]['scalingFactor'].append(scalingFactor)\n",
    "        results[subswathID]['correlationCoefficient'].append(correlationCoefficient)\n",
    "        results[subswathID]['fitResidual'].append(fitResidual)\n",
    "                \n",
    "# Save the results for individual file in NPZ format\n",
    "np.savez(s1.name.split('.')[0] + '_noiseScaling.npz', **results)\n",
    "\n",
    "# At this point we obtained statistics for many files and ready to the 2nd stage that is\n",
    "# aggregated statistics processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "# Stage 2. Processing of aggregated statistics #\n",
    "################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once we have statistics for the training files we may start stage 2 to get final results on the noise scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty lists for aggregated results for each sub-swath from each npz file\n",
    "powerDifference = {'%s%s' % (s1.obsMode, li): [] for li in range(1, ({'IW':3, 'EW':5}[s1.obsMode]+1))}\n",
    "scalingFactor = {'%s%s' % (s1.obsMode, li): [] for li in range(1, ({'IW':3, 'EW':5}[s1.obsMode]+1))}\n",
    "correlationCoefficient = {'%s%s' % (s1.obsMode, li): [] for li in range(1, ({'IW':3, 'EW':5}[s1.obsMode]+1))}\n",
    "fitResidual = {'%s%s' % (s1.obsMode, li): [] for li in range(1, ({'IW':3, 'EW':5}[s1.obsMode]+1))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing S1A_IW_GRDH_1SDV_20200607T075151_20200607T075220_032908_03CFD7_9E14_noiseScaling.npz\n"
     ]
    }
   ],
   "source": [
    "# Get the list of npz files with individual statistics\n",
    "import glob\n",
    "npzFiles = glob.glob('*noiseScaling*.npz')\n",
    "\n",
    "# Loop over the files\n",
    "for npzFile in npzFiles:\n",
    "    print('importing %s' % npzFile)\n",
    "    npz = np.load(npzFile)\n",
    "    npz.allow_pickle = True\n",
    "    \n",
    "    for iSW in range(1, ({'IW': 3, 'EW': 5}[s1.obsMode])+1):    \n",
    "        # Get number of sub-blocks\n",
    "        numberOfSubblocks = np.unique([\n",
    "                    len(npz['%s%s' % (s1.obsMode,iSW)].item()[key])\n",
    "                    for key in ['scalingFactor', 'correlationCoefficient', 'fitResidual']])\n",
    "        \n",
    "        # Check if the number of sub-blocks is consistent for all parameters\n",
    "        if numberOfSubblocks.size != 1:\n",
    "                print('*** numberOfSubblocks are not consistent for all estimations.')\n",
    "                continue\n",
    "        # Unpack the number of sub-blocks\n",
    "        numberOfSubblocks = numberOfSubblocks.item()\n",
    "        \n",
    "        # Calculate a value of intermediate sigma0 value for each sub-block\n",
    "        powerDifference['%s%s' % (s1.obsMode,iSW)].append([\n",
    "                  np.nanmean(10*np.log10(npz['%s%s' % (s1.obsMode,iSW)].item()['sigma0'][li]))\n",
    "                - np.nanmean(10*np.log10(npz['%s%s' % (s1.obsMode,iSW)].item()['noiseEquivalentSigma0'][li]))\n",
    "                for li in range(numberOfSubblocks) ])\n",
    "        \n",
    "        # Collect a set of values of scaling factors, correlation coefficients and residuals for each sub-block\n",
    "        scalingFactor['%s%s' % (s1.obsMode,iSW)].append(npz['%s%s' % (s1.obsMode,iSW)].item()['scalingFactor'])\n",
    "        correlationCoefficient['%s%s' % (s1.obsMode,iSW)].append(npz['%s%s' % (s1.obsMode,iSW)].item()['correlationCoefficient'])\n",
    "        fitResidual['%s%s' % (s1.obsMode,iSW)].append(npz['%s%s' % (s1.obsMode,iSW)].item()['fitResidual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists for noise scaling parameters and their confidence intervals for final results\n",
    "noiseScalingParameters = {'%s%s' % (s1.obsMode, li): {} for li in range(1, ({'IW':3, 'EW':5}[s1.obsMode]+1))}\n",
    "noiseScalingParametersRMSE = {'%s%s' % (s1.obsMode, li): {} for li in range(1, ({'IW':3, 'EW':5}[s1.obsMode]+1))}\n",
    "\n",
    "# Loop over sub-swaths to obtain final noise scaling factors for each sub-swath\n",
    "for iSW in range(1, ({'IW': 3, 'EW': 5}[s1.obsMode])+1):   \n",
    "    # Open agregated lists of parameters as NumPy vector for sub-swath\n",
    "    # Vector of intermediate sigma0\n",
    "    pd = np.hstack(powerDifference['%s%s' % (s1.obsMode,iSW)])\n",
    "    # Vector of of noise scaling factor\n",
    "    sf = np.hstack(scalingFactor['%s%s' % (s1.obsMode,iSW)])\n",
    "    # vector of correaltion coefficient between raw sigma0 and scaled nosie\n",
    "    cc = np.hstack(correlationCoefficient['%s%s' % (s1.obsMode,iSW)])\n",
    "    # Vector of errors of fitting of the scaling factor (K)\n",
    "    fr = np.hstack(fitResidual['%s%s' % (s1.obsMode,iSW)])\n",
    "\n",
    "    # Calculate vector with weights for fitting: higher weights for high correlation and low RMSE from K-fitting\n",
    "    w = cc / fr\n",
    "    \n",
    "    # Note: Fitting of K to powerDifference with degree=0\n",
    "    # Here we find optimal value of K (just one value since degree of fitted polynom is 0).\n",
    "    # That optimal value corresponds to:\n",
    "    #  * high density of powerDifference values: This high density appears where powerDifference\n",
    "    #    is low. I.e. where signal is low (low wind conditions).\n",
    "    #  * high weights: where correlation is high and rmse is low\n",
    "    # y using this fitting we avoid neccesity to choose scenes with low wind manualy.\n",
    "    fitResults = np.polyfit(pd, sf, deg=0, w=w)\n",
    "\n",
    "    # Results\n",
    "    # Noise scaling coefficient\n",
    "    noiseScalingParameters['%s%s' % (s1.obsMode,iSW)] = fitResults[0]\n",
    "    # Confidence interval\n",
    "    noiseScalingParametersRMSE['%s%s' % (s1.obsMode,iSW)] = np.sqrt(np.sum((fitResults[0]-sf)**2 * w) / np.sum(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise scaling parameters for each sub-swath:\n",
      "{'IW1': 1.0525003487515774, 'IW2': 1.003359997763131, 'IW3': 1.0945965379679081}\n",
      "\n",
      "Confidence intervals:\n",
      "{'IW1': 0.03060775683092379, 'IW2': 0.00967053603311147, 'IW3': 0.009314693037954078}\n"
     ]
    }
   ],
   "source": [
    "# Now we obtained noise scaling factors for each sub-swath as well as\n",
    "# their confident intervals and may print it out\n",
    "\n",
    "print('Noise scaling parameters for each sub-swath:\\n%s' % noiseScalingParameters)\n",
    "print('\\nConfidence intervals:\\n%s' % noiseScalingParametersRMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
